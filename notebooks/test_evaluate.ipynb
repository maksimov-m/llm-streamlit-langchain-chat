{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.chdir('../app')\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from ragas.evaluation import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, AnswerRelevancy, ContextPrecision\n",
    "from ragas.run_config import RunConfig\n",
    "\n",
    "from components.router import Router\n",
    "from components.llm import LLM\n",
    "from components.retriever import Retriever\n",
    "from workflow.rag_workflow import RAGWorkflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 15:58:58 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:211 - __init__() - Use pytorch device_name: mps\n",
      "2025-04-06 15:58:58 - sentence_transformers.SentenceTransformer - INFO - SentenceTransformer.py:219 - __init__() - Load pretrained SentenceTransformer: all-mpnet-base-v2\n",
      "2025-04-06 15:59:03 - semantic_router.utils.logger - INFO - base.py:114 - from_file() - Loading route config from ./artifacts/router_config.json\n",
      "2025-04-06 15:59:03 - semantic_router.utils.logger - WARNING - base.py:442 - _get_index() - No index provided. Using default LocalIndex.\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(\n",
    "    model='llama-3-8b-instruct-8k',\n",
    "    model_provider='openai',\n",
    "    api_url='https://llama3gpu.neuraldeep.tech/v1',\n",
    "    api_key='API_KEY',\n",
    ")\n",
    "\n",
    "retriever = Retriever(\n",
    "    artifacts_path='./artifacts',\n",
    "    dataframe_path='all_data.csv',\n",
    "    embedding_model_name='all-mpnet-base-v2',\n",
    ")\n",
    "\n",
    "router = Router(\n",
    "    artifacts_path='./artifacts',\n",
    "    router_config_path='router_config.json',\n",
    "    index_router_path='index_router.pickle'\n",
    ")\n",
    "\n",
    "workflow = RAGWorkflow(\n",
    "   llm=llm,\n",
    "   router=router,\n",
    "   retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка датасета для проверки RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Как чистить уши французскому бульдогу?</td>\n",
       "      <td>Используйте специальный лосьон для чистки ушей...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Какие требования предъявляются к древесине?</td>\n",
       "      <td>Древесина должна быть высокого качества, обраб...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Что делать, если кожа шелушится?</td>\n",
       "      <td>Увлажняйте ее и используйте мягкие эксфолианты.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Что такое постакне?</td>\n",
       "      <td>Это следы после прыщей: рубцы, пятна, неровности.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Можно ли уволить работника без его согласия?</td>\n",
       "      <td>Да, если есть законные основания, например, со...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question  \\\n",
       "115        Как чистить уши французскому бульдогу?   \n",
       "21    Какие требования предъявляются к древесине?   \n",
       "168              Что делать, если кожа шелушится?   \n",
       "196                           Что такое постакне?   \n",
       "327  Можно ли уволить работника без его согласия?   \n",
       "\n",
       "                                          ground_truth  \n",
       "115  Используйте специальный лосьон для чистки ушей...  \n",
       "21   Древесина должна быть высокого качества, обраб...  \n",
       "168    Увлажняйте ее и используйте мягкие эксфолианты.  \n",
       "196  Это следы после прыщей: рубцы, пятна, неровности.  \n",
       "327  Да, если есть законные основания, например, со...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../tests/clear_data.csv')\n",
    "validation_set = data[['question', 'answer']].rename(columns={'answer': 'ground_truth'}).sample(10)\n",
    "validation_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from datasets import Dataset \n",
    "\n",
    "def create_data_for_ragas(workflow, eval_data):\n",
    "    rag_dataset = []\n",
    "    for _, row in tqdm(eval_data.iterrows()):\n",
    "        result = workflow.graph.invoke(\n",
    "            input={\n",
    "            \"question\": row['question'],\n",
    "            \"messages\": []\n",
    "            },\n",
    "            config={\n",
    "                \"configurable\": {\n",
    "                    \"thread_id\": 'qwdhou',\n",
    "                }\n",
    "            } \n",
    "        )\n",
    "\n",
    "        rag_dataset.append(\n",
    "            {\n",
    "                \"question\": row['question'],\n",
    "                \"answer\": result['messages'][-1].content,\n",
    "                \"retrieved_contexts\": result['context'],\n",
    "                \"ground_truth\": row['ground_truth']\n",
    "            }\n",
    "        )\n",
    "\n",
    "    rag_df = pd.DataFrame(rag_dataset)\n",
    "    rag_eval_dataset = Dataset.from_pandas(rag_df)\n",
    "\n",
    "    return rag_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s]\n",
      "2025-04-06 16:00:45 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s]\n",
      "2025-04-06 16:00:47 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n",
      "2025-04-06 16:00:48 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s]\n",
      "2025-04-06 16:00:49 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 29.31it/s]\n",
      "2025-04-06 16:00:50 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s]\n",
      "2025-04-06 16:00:52 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 18.44it/s]\n",
      "2025-04-06 16:00:54 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "2025-04-06 16:00:56 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s]\n",
      "2025-04-06 16:00:57 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s]\n",
      "2025-04-06 16:00:59 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "10it [00:15,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "qa_ragas_baseline = create_data_for_ragas(workflow, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Как чистить уши французскому бульдогу?',\n",
       " 'answer': 'Используйте специальный лосьон для чистки ушей и ватные диски.',\n",
       " 'retrieved_contexts': ['Как чистить уши французскому бульдогу? Используйте специальный лосьон для чистки ушей и ватные диски.',\n",
       "  'Почему у французского бульдога большие уши? Это результат селекции, такие уши стали визитной карточкой породы.',\n",
       "  'Какой рост у французского бульдога? Рост в холке — около 25–35 см.',\n",
       "  'Можно ли путешествовать с французским бульдогом? Да, но важно учитывать их чувствительность к перепадам температуры.',\n",
       "  'Как выглядит французский бульдог? Это компактная собака с мускулистым телом, короткой шерстью, большими ушами и характерной плоской мордой.'],\n",
       " 'ground_truth': 'Используйте специальный лосьон для чистки ушей и ватные диски.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_ragas_baseline[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка метрик\n",
    "Метрики:\n",
    "- [Context Precision](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/context_precision/?h=context)\n",
    "- [Context Recall](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/context_recall/?h=context)\n",
    "- [Faithfulness](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/faithfulness/?h=faithfulness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_config = RunConfig(max_workers=2, timeout=180, max_wait=120)\n",
    "evaluator = LangchainLLMWrapper(llm.model)\n",
    "embedding = LangchainEmbeddingsWrapper(retriever) # такой вариант не работает в логах видно что нет атрибута "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше в логах оценки метрик видна ошибка для модели векторизации. Так как LangchainEmbeddingsWrapper(класс RAGAS) не умет работать с Semantic Transformer\n",
    "\n",
    "2025-04-06 15:26:44 - ragas.executor - ERROR - executor.py:104 - wrapped_callable_async() - Exception raised in Job[3]: AttributeError('Retriever' object has no attribute 'embed_query')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/30 [00:00<?, ?it/s]2025-04-06 16:01:13 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:13 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:   3%|▎         | 1/30 [00:01<00:53,  1.83s/it]2025-04-06 16:01:14 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:15 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:15 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:16 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:17 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:   7%|▋         | 2/30 [00:05<01:28,  3.16s/it]2025-04-06 16:01:18 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  10%|█         | 3/30 [00:06<00:56,  2.10s/it]2025-04-06 16:01:18 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:19 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:19 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  13%|█▎        | 4/30 [00:08<00:49,  1.92s/it]2025-04-06 16:01:20 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:21 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:22 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:23 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  17%|█▋        | 5/30 [00:11<00:59,  2.38s/it]2025-04-06 16:01:24 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:25 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:26 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  20%|██        | 6/30 [00:15<01:08,  2.85s/it]2025-04-06 16:01:27 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:28 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  23%|██▎       | 7/30 [00:16<00:56,  2.44s/it]2025-04-06 16:01:28 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:29 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:29 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  27%|██▋       | 8/30 [00:18<00:45,  2.07s/it]2025-04-06 16:01:30 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:32 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  30%|███       | 9/30 [00:20<00:46,  2.19s/it]2025-04-06 16:01:32 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:33 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:34 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  33%|███▎      | 10/30 [00:22<00:42,  2.11s/it]2025-04-06 16:01:34 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:35 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:36 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  37%|███▋      | 11/30 [00:24<00:39,  2.06s/it]2025-04-06 16:01:37 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:38 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:39 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:40 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  40%|████      | 12/30 [00:28<00:49,  2.77s/it]2025-04-06 16:01:41 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:42 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  43%|████▎     | 13/30 [00:30<00:42,  2.48s/it]2025-04-06 16:01:42 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  47%|████▋     | 14/30 [00:30<00:28,  1.77s/it]2025-04-06 16:01:43 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:44 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:45 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:46 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:47 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  50%|█████     | 15/30 [00:36<00:42,  2.83s/it]2025-04-06 16:01:48 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:49 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  53%|█████▎    | 16/30 [00:37<00:34,  2.43s/it]2025-04-06 16:01:49 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:50 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:50 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:51 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:53 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:53 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  60%|██████    | 18/30 [00:41<00:26,  2.20s/it]2025-04-06 16:01:54 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:55 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  63%|██████▎   | 19/30 [00:43<00:24,  2.20s/it]2025-04-06 16:01:55 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  67%|██████▋   | 20/30 [00:43<00:16,  1.67s/it]2025-04-06 16:01:56 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:57 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:58 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:01:59 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:02:01 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:02:02 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  70%|███████   | 21/30 [00:50<00:28,  3.14s/it]2025-04-06 16:02:03 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  73%|███████▎  | 22/30 [00:51<00:19,  2.42s/it]2025-04-06 16:02:04 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:02:05 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  77%|███████▋  | 23/30 [00:54<00:17,  2.53s/it]2025-04-06 16:02:07 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:02:08 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  80%|████████  | 24/30 [00:56<00:14,  2.48s/it]2025-04-06 16:02:08 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:02:09 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:02:10 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  83%|████████▎ | 25/30 [00:58<00:11,  2.31s/it]2025-04-06 16:02:10 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:02:10 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:02:12 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  87%|████████▋ | 26/30 [01:00<00:08,  2.16s/it]2025-04-06 16:02:12 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  90%|█████████ | 27/30 [01:00<00:04,  1.66s/it]2025-04-06 16:02:13 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:02:14 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  93%|█████████▎| 28/30 [01:02<00:03,  1.65s/it]2025-04-06 16:02:14 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:02:15 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:02:15 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:02:17 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-06 16:02:18 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  97%|█████████▋| 29/30 [01:06<00:02,  2.48s/it]2025-04-06 16:02:19 - httpx - INFO - _client.py:1740 - _send_single_request() - HTTP Request: POST https://llama3gpu.neuraldeep.tech/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating: 100%|██████████| 30/30 [01:08<00:00,  2.27s/it]\n"
     ]
    }
   ],
   "source": [
    "baseline_result = evaluate(  \n",
    "  dataset=qa_ragas_baseline,  \n",
    "  metrics=[  \n",
    "      ContextPrecision(),  \n",
    "      LLMContextRecall(),  \n",
    "      Faithfulness(),   \n",
    "    ],\n",
    "  llm=evaluator,\n",
    "  run_config=my_config,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.9500, 'context_recall': 1.0000, 'faithfulness': 0.9667}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывод оценок полученных на основе датасета\n",
    "baseline_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
